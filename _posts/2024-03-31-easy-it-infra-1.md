---
layout: post
title: 초등학생도 이해하는 IT 인프라 구조 1편
subtitle: 큰 그림 그리기
author: honghyeong
categories: system
tags: [system]
sidebar: []
---

우리가 살아가는데 기반이 되는 생활 인프라를 떠올리면 가스, 수도, 전기 설비를 떠올릴 수 있다.
<br>
이러한 인프라는 내부적인 작동과정을 자세하게 이해하지 않아도 일상생활에서 손쉽게 이용가능하다.

“IT 인프라”도 마찬가지이다. IT 서비스를 운영하는데 기반이 되는 설비이며, IT 서비스 사용자들은 내부 작동방식을 자세히 알지 못해도 손쉽게 사용할 수 있다는 공통점이 있다.
IT 인프라는 어떤 서비스든지 물리적인 기본적인 구성은 유사하고, 서비스 특성에 맞게 설계방식에서 조금의 차이만 있는 정도이다.

IT 인프라를 떠올릴 때, Cloud, Docker, k8s… “와 같은 fancy한 IT 기술 떠올리는 사람도 있을 것이다.
하지만 컴퓨터공학도로써 `AI SRE`라는 로드맵을 고민하면서 자주 느끼는 것은, 핫하다고 장점만이 있는 것이 아니라, 모든 기술에는 `Trade Off`가 있다는 것이다. 신기술이라고 무작정 좋은 것이 아니라, 기존에 있었던 "어떤 문제를 해결하려고 그 기술이 등장했으며", "각 기술들은 어떤 장단점을 갖고 있는지", "어떠한 시스템에 사용하면 좋을지", "그 기술의 기반에는 어떤 CS지식이 숨어있는지"를 제대로 이해한다면 이후에 어떠한 새로운 기술이 나와도 빠르게 이해하고, 서비스의 특성에 맞는 적절한 기술을 도입할 수 있는 역량을 기를 수 있을 것이라고 생각한다.
지금의 IT 인프라가 있기까지 어떤 기술적 한계를 어떻게 이겨내왔는지 알고, 이것을 기반으로 앞으로 새로운 Infra, Devops 기술이 나오더라도 본질은 비슷하니, 쉽고 빠르게 습득할 수 있을 것이라고 생각한다.

> 그래서 나는 이 포스팅을 통해서 System Infra 관련 도서를 공부하거나, SE 직무를 수행하며 알게된 내용을 최대한 쉽게, 초등학생도 이해할 수 있게 기록하고, 계속해서 내용을 붙여나가려고 한다.

큰 틀은 아래와 같다.

1. 인프라에 대한 기본구조에 대해 이해한다. IT 인프라 기본 구조는 크게 변하지않는다. 모두 비슷한 모습을 하고있다.
2. 기술 발전에 따라 인프라 구조(시스템 아키텍처)가 어떻게 변해왔으며, 기존의 어떤 문제점을 해결하려했는지 이해한다.
3. 그 문제점을 해결할 수 있었던 기술은 어떤 장단점을 갖고있는지, 그 기반이 되는 CS 지식은 무엇이 있을지 이해한다.

이렇게 쌓은 인프라 지식을 바탕으로 세세한 부분을 채워나가면서 추가적으로 궁금한 주제(OS, MW, DB, 가상화, 컨테이너, Cloud, Kubernetes, Appl)에 대해서 더 쉽고 깊게 알아보려고 한다.

<br>

## 1. 인프라 아키텍처의 기본 구조

인프라의 기본 구조는 기존 아키텍처의 문제점을 해결하기 위해서 계속해서 변해왔다.

- 메인 프레임 시스템 → 분산형 시스템
- 하나의 거대한 컴퓨터(진공관) → 노트북

이제부터는 위에서 말했던 것처럼, 어떤 문제를 해결하려고 어떤 새로운 아키텍처가 고안됐고, 기존의 아키텍처에 비해 어떠한 장단점이 있는지 생각해보자.

|           | 집약형 아키텍처                                                                                                                               | 분산형 아키텍처                                                                                                  |
| --------- | --------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------- |
| 설명      | 하나의 큰 서버로 하나의 시스템을 구축                                                                                                         | 여러 대의 작은 서버로 하나의 시스템을 구축                                                                       |
| 장점      | 하나의 큰 메인프레임 서버만 관리하면 되므로 운영 난이도가 쉽다.대부분의 구성요소(cpu, mem, …)가 이중화 돼있어 안정성이 높다.                  | 집약형 아키텍처에 비해서 서버를 확장하는 비용이 저렴하다. 따라서 확장성이 좋으며, 비용 효율적이다.               |
| 단점      | 하나의 메인프레임은 도입비용은 매우 비싸다. 서버를 도입할때의 초기 비용(서버 비용, 운영 비용)이 높아 확장성이 좋지않고, 비용 효율적 이지않다. | 집약형 아키텍처에 비해 관리해야하는 서버가 많아지면서 구조가 더 복잡하고, 운영이 더 어렵다.                      |
| 개선된 점 |                                                                                                                                               | 집약형 아키텍처에 비해서 서버 도입 비용과 유지 비용이 저렴하여, 서버를 손쉽게 확장할 수 있으며, 비용 효율적이다. |

분산형 아키텍처에서는 서버를 분산(수직 분산, 수평 분산)하여 집약형의 문제점(서비스 가용성과 확장성)을 보완한다.

| 아키텍처 | 수직 분산형 아키텍처                                                | 수평 분산형 아키텍처                                  |
| -------- | ------------------------------------------------------------------- | ----------------------------------------------------- |
| 설명     | 서버 역할에 따라서 계층을 나눠서 분산하는 아키텍처(3-tier)          | 같은 역할을 하는 서버를 여러대 두어 분산하는 아키텍처 |
| 장점     | 역할 별로 부하를 분산하여 서비스 확장성 및 가용성을 확보할 수 있다. |

요청의 종류에 따라서, 모든 티어를 거치지않고 앞단에서 신속하게 처리할 수 있다. | 특정 서버에 장애가 생겨도, 같은 역할을 하는 서버가 있으므로 안정성이 높다.

같은 역할을 하는 서버들에게 부하를 분산하여 서비스 확장성 및 가용성을 확보할 수 있다.

|
| 단점 | 더 복잡한 구조로 인해서 운영 및 관리가 더 어렵다. | 더 복잡한 구조로 인해서 운영 및 관리가 더 어렵다. |

수평 분산형 아키텍처는 시스템의 데이터 공유 / 연동 유무에 따라서 두 가지 아키텍처로 한번 더 나눌 수 있다. 단순히 여러개의 독립적인 시스템을 수평으로 두는 방법이 있는 반면 시스템의 데이터가 동기화되어야 한다면 별도의 기술이 필요하여 관리와 운영이 더 어려워진다.

| 아키텍처 | 단순형 수평분산 아키텍처                                                                                  | 공유형 수평분산 아키텍처                                                                                                                                  |
| -------- | --------------------------------------------------------------------------------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------- |
| 설명     | 단순히 같은 기능을 하는 시스템을 여러개 두는 아키텍처, 각 시스템은 독립적이므로 데이터가 공유되지 않는다. | 같은 기능을 하는 시스템을 여러개 두고 데이터도 공유되도록 하는 아키텍처 (넷플릭스가 지역별로 다른 시스템이 있고, 영상 데이터가 공유된다고 생각하면 된다.) |
| 장점     | 각 시스템은 완전히 독립적이므로, 하나의 시스템에 발생한 장애가 다른 시스템으로 전파되지 않는다.           |

각 시스템으로 부하를 분산할 수 있으므로, 처리 성능이 올라가고, 확장성이 향상된다. | 각 시스템간의 데이터를 공유(동기화)할 수 있다.

각 시스템으로 부하를 분산할 수 있으므로, 처리 성능이 올라가고, 확장성이 향상된다. |
| 단점 | 각 시스템 간의 데이터 공유가 어렵다. | 데이터를 공유하는 계층은 확장성에 제약이 생긴다.

공유 데이터에 대한 운영 및 관리가 어렵다. 데이터 동기화로 인한 장애 전파 가능성을 고려해야한다 |

위의 아키텍처에서 예상치못한 장애를 대비하여 안정적인 서비스를 운영하기 위해서는 가용성 확보형 아키텍처를 도입하기도 한다. Fault Tolerance라고도 한다.

**가용성 확보형 아키텍처**

이중화 서버 또는 지리적으로 떨어진 곳에 DR용 시스템을 추가적으류 구축하여, 일반적인 상황이 아닌 재해 및 장애상황에 대응하기 위한 시스템 가용성을 확보하는 아키텍처이다.

- 장점
  - 기존의 수직, 수평 분할형 아키텍처에 비해 장애 및 재난상황에 대한 안정성을 확보할 수 있다.
- 단점
  - 어떤 상황에서든 바로 서버를 투입할 수 있도록 해야한다.
  - 하나의 서버에서 업데이트가 있을 경우, 이중화 서버 및 DR 서버에 동일하게 적용해야한다.
  - 더 많은 서버를 구매하고 관리해야하므로, 인프라 구축 비용이 N배가 된다.
  - 데이터 동기화가 중요하고, 여기서 추가적인 비용이 발생한다.

| 아키텍처 | 이중화(Active-Stand by)                                                                              | 재난 복구(DR)                                                                                                            |
| -------- | ---------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------ |
| 설명     | 서버를 이중화하여, Active 서버에 장애가 생긴 경우, 신속하게 예비 서버를 가동(Fail-Over)하는 아키텍처 | 지진, 해일 등 재난 상황을 고려하여 지리적으로 멀리 떨어진 곳에 서비스를 지속할 수 있는 최소 시스템을 만들어두는 아키텍처 |

# 2. 데이터센터와 서버의 구조

아키텍처를 이루는 서버들은, 우리가 집에서 사용하는 PC처럼 전원을 연결하고, 네트워크를 연결해야한다. 기업에서 IT 인프라를 구축하는데 사용하는 물리서버들은 데이터센터라는 공간에 모여있고 랙(Rack)이라는 선반에 올라가게 된다. (Cloud 인프라도 결국에는 클라우드를 제공하는 기업의 물리서버 위에서 구성된다.)

데이터센터는 여러 서버들을 관리할 수 있는 환경(전력, 공간, 냉각시설 등)을 갖추고있어 많은 서버들을 운영할 수 있는 최적의 환경이다. 데이터센터의 수많은 랙(Rack)에는 하드웨어를 고정시킬 수 있는 선반이 있어, 네트워크 장비, 스토리지, 서버들을 선반에 고정시킬 수 있다.

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/497f4b2e-b1ea-4694-b568-34b34ad316bc/55514419-fba6-4bdd-9115-6292260dec95/Untitled.png)

서버는 랙에 빈 공간이 있다고 아무렇게나 꽂지는 못한다. 서버가 들어갈 수 있는 충분한 공간(유닛 수)이 있는지, 전력(서버 전력 요구량)은 충분한지, 서버가 연결되어야하는 네트워크 장비(스위치)와 케이블로 연결할 수 있는 거리인지. 충분히 다양한 점을 고려해야한다.

이제 데이터 센터안에 있는 서버를 뜯어보자.

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/497f4b2e-b1ea-4694-b568-34b34ad316bc/a72ecfa4-4b91-42c1-803f-18852b5102a3/Untitled.png)

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/497f4b2e-b1ea-4694-b568-34b34ad316bc/febca926-5607-449b-8ed8-1b1148ff4d74/Untitled.png)

서버는 위의 그림처럼 여러 컴포넌트들이 버스(데이터 전송 통로)로 연결되어있는 구조이다. 기본적으로 집에서 사용하는 PC와 물리적인 기본 구성은 비슷하지만, 컴포넌트들이 이중화(전원, NIC,…) 돼있는 안정성과 컴포넌트들이 훨씬 고스펙이라는 측면에서 조금의 차이가 있을 뿐이다.

위 사진 속 각각의 컴포넌트가 무슨 일을 하는지 지금은 몰라도 된다. 결국에 이 포스팅을 읽다보면 모두 알 수 있다. 간단히 설명하겠다. 조금 더 자세히 알고싶다면 ChatGPT 를 활용해서 찾아보기를 권한다.

- `PCI Express 슬롯 : 외부장치를 연결하는 곳`
- `칩셋(PCH)`
- `BMC` = 서버 하드웨어 장애가 발생한 경우, BMC를 통해 서버의 상태를 확인할 수 있고, 원격 재시동 가능

서버의 구조는 각 컴포넌트의 성능이 개선되거나 또는 배치가 변경되면서 조금씩 다르지만, 기본적인 구성은 동일하다고 보면된다.

- `성능 개선 > CPU 클럭 수 증가`
- `배치 변경 > 멀티 프로세서 도입, 듀얼 채널`

서버는 일반적으로 위와 같은 하드웨어 구조를 가지고,

입출력장치 또는 프로세스가 OS를 통해 명령을 내리면 CPU가 중앙에서 명령어를 처리하면서 다른 컴포넌트(메모리, 보조기억장치, 입출력 장치)를 동작시키며 다양한 업무(프린터, 화면출력, 애플리케이션 실행 등)를 수행한다.

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/497f4b2e-b1ea-4694-b568-34b34ad316bc/9094fd4c-5765-44dc-b320-80e5debdd5a4/Untitled.png)

이제 각각의 컴포넌트(CPU, 메모리, HDD, NIC, BUS… ) 에 대해서 자세히 알아보자.

### CPU

CPU(Central Processing Unit, 중앙 처리 장치)는 고성능 연산 장치이다.

CPU는 기억장치에 저장돼있는 명령어와 데이터를 활용해서 연산을 수행하고, 결과를 반환하는 식으로 동작한다.

- `기억장치 = 레지스터 + 캐시메모리 + 메모리 + 보조기억장치(HDD, SSD)`
- `명령 전달 순서`
  - `CPU가 자체적으로 연산을 수행하지는 않음`
  - `프로세스 & 입출력장치가 명령 ⇒ OS(운영체제) ⇒ 기억장치(명령 + 데이터) ⇒ CPU(연산)`

이러한 연산을 수행하는 최소 단위를 코어(core)라고 하며, 최근에는 하나의 CPU에 멀티 코어가 존재한다. ( = 멀티코어 아키텍처) 각각의 코어는 각각 독립된 처리를 수행할 수 있고, 현대의 CPU는 주로 멀티코어 + 멀티프로세서로 구성돼있다.

- `멀티코어 = 하나의 물리적인 CPU 부품에 여러 코어가 존재`
- `멀티프로세서 = 하나의 서버에 여러 CPU 부품을 장착`
- `1소켓 8core, 2소켓 ⇒ 16core`

자, 그럼 실제로는 CPU가 어떻게 구성돼있는지 확인 해보자.

아래 사진과 같이 CPU의 스펙은 보통 멀티코어, 멀티프로세스, 클럭수로 설명된다.

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/497f4b2e-b1ea-4694-b568-34b34ad316bc/0cac47b8-9042-49f0-8ac2-b404a68afbb5/Untitled.png)

- `CPU 스펙 사진`
  - `3.2GHz는 1초당 3.2 x 10^9의 명령을 수행할 수 있다는 것이다. 제조사는 크게 AMD, 인텔로 나눌 수 있다.`

### 메모리

전기적인 처리로 데이터를 저장하여, 전원이 끊기면 데이터가 사라지는 기억장치이다. 데이터가 휘발되는 대신, 물리적으로 데이터를 저장하는 장치에 비해서 데이터 접근 속도가 빠르다. 메모리는 CPU와 채널(Channel)이라는 데이터 경로로 직접 연결되어있다.

기억장치는 CPU에 비해서 상대적으로 느린 속도로 동작한다. 따라서, 자주 사용하는 데이터 & 명령어를 최대한 CPU에 가까운 곳에, 동작이 빠른 메모리에 두어 CPU 연산이 지연되는 것을 최소화한다. 이것을 메모리 계층 구조라고 한다.

L1 캐시, L2캐시, L3캐시, 메모리 순으로 코어와 가까운 곳에 위치한다. 따라서 자주 사용하는 명령어일수록 코어와 가까운 캐시 메모리에 저장하여 지연시간(레이턴시)를 최소화한다. 메모리에 접근하기 위해서는 메모리 컨트롤러를 통해서 접근해야하므로 상대적으로 많은 레이턴시가 발생한다.

- `메모리 계층구조란?`
  - `기억장치는 데이터 접근 속도가 빠를수록, 데이터 저장공간은 작아진다.`
  - `CPU에서 빈번하게 사용되는 데이터, 명령어 순서대로 CPU에 가깝게 두어 CPU 지연시간을 최소화한다.`
  - `접근 속도 : L1 캐시 > L2 캐시 > L3캐시 > 메모리 (Micro sec)> 비휘발성 저장 장치(Mili Sec)`
  - `저장공간 크기 : L1캐시 < L2캐시 < L3캐시 < 메모리 < 비휘발성 저장 장치(HDD, SSD)`
- 공간적 지역성(Cache Locality)
- 시간적 지역성(Temporal Locality)
- 메모리 인터리빙(Memory Interleaving)

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/497f4b2e-b1ea-4694-b568-34b34ad316bc/d97b2388-6bef-4a52-9da9-8af948674baf/Untitled.png)

### I/O 장치 :: 보조기억장치(HDD/SSD) + 스토리지

메모리 계층구조에 따라서 보조기억장치는 메모리보다 CPU에서 더 먼곳에 배치된다. 메모리에 비해 데이터 접근속도가 느린 대신, 대용량으로 저장가능하고, 전원이 끊겨도 데이터가 저장된다. HDD는 CD의 자성을 이용해서 데이터를 저장하고, SSD는 전자를 이용해서 데이터를 저장한다. 물리서버에는 OS 설치 및 데이터 저장 목적으로 여러 보조기억장치를 Raid Controller에 장착하여 데이터 안정성을 확보한다.

- `Raid Controller`
- `SATA, SAS, NVMe의 차이`

서버 자체적으로 갖고있는 보조기억장치의 용량에는 한계가 있으므로, 수많은 데이터를 저장해야할 때는 스토리지를 활용한다. 스토리지란, 수많은 HDD를 장착하여 여러 서버의 대용량 데이터를 저장하려는 목적으로 사용하는 하드웨어이다. 자체적으로 CPU & 캐시 메모리를 갖고있어 빠른 속도로 데이터를 쓰거나 읽을 수 있다.

서버는 스토리지의 디스크와 직접 데이터를 교환하지않고, 캐시를 통해서 데이터를 교환한다.

사용하는 스토리지의 종류는 크게 3가지(Block, File, Object)가 있는데, 저장 방식에 차이가 있으며 스토리지가 서버와 연결하는데 필요한 하드웨어도 다르다.

- `라이트 스루(Write Through)`
- `라이트 백(Write Back)`
- `SAN과 NAS의 차이(저장방식과 물리 구성 측면에서)`
- `오브젝트 스토리지란`

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/497f4b2e-b1ea-4694-b568-34b34ad316bc/33049a6a-7a68-49d9-a0a2-ad517dcdffef/Untitled.png)

### I/O 장치 :: 네트워크 인터페이스

서버를 다른 장치와 연결할 수 있는 인터페이스를 말한다. 해당 인터페이스(포트)에 케이블을 연결해서 다른 하드웨어(스위치, 스토리지, … )와 연결하여 데이터를 주고받을 수 있다. 보통 서버에 LAN 어댑터(NIC)이 장착되지만, 스토리지 연결목적으로 FC 어댑터(HBA)를 추가하여 장착할 수도 있다. 자세한 네트워크 개념은 이후 설명하겠다.

### I/O 장치 :: 서버내의 데이터 전송 경로

서버 내 데이터 전송 회선은 연결 대상과 목적에 따라 다양하다.

- CPU ↔ CPU 데이터 전송 목적 = UPI(Ultra Path Interconnect)
- CPU ↔ 메모리 데이터 전송 목적 = 채널(Channel)
- CPU ↔ 입출력장치 데이터 전송 목적 = PCI 회선
- CPU ↔ 처리 속도가 늦어도 되는 저속 입출력(네트워크, USB, …) 목적 = PCH 칩셋(I/O컨트롤러) + DMI

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/497f4b2e-b1ea-4694-b568-34b34ad316bc/981f9d90-0a65-4ebd-9780-84128d7a4126/Untitled.png)

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/497f4b2e-b1ea-4694-b568-34b34ad316bc/68f88139-4153-4983-a46f-c1e7566ca5da/Untitled.png)

### I/O 장치 :: 버스

버스는 서버 내 컴포넌트들을 연결시키는 회선을 말한다. 컴포넌트간 데이터의 전송속도는 버스의 대역폭(한번에 얼마나 보낼 수 있는지)과 전송속도(1초에 몇 번 전송하는지)에 의해 결정된다.

예를 들어, 버스 인터페이스 규격 중 하나인 PCI Express 3.0은 버스 1회선 당 2GB/s 전송이 가능하다.

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/497f4b2e-b1ea-4694-b568-34b34ad316bc/4122783f-e99c-4e90-a36f-f7de09e60f7a/Untitled.png)

위에서 살펴봤던 것처럼, CPU에 가까울 수록 버스의 대역폭이 높고, 멀수록 버스의 대역폭이 낮다.

외부 연결장치와 연결을 검토할 때 외부 연결장치의 데이터 전송속도가 버스의 전송속도보다 높아 병목현상이 발생하지않도록 하는 것이 중요하다.

- `병목현상`

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/497f4b2e-b1ea-4694-b568-34b34ad316bc/986bf5ab-5f01-4aaf-8d8d-ff8db71fb959/Untitled.png)

# 3. 3계층형 시스템

### 3계층형 시스템

앞에서 소개했던 “수직 분할형 아키텍처”는 현재 많은 IT 서비스에서 일반적으로 채택되는 아키텍처이다. 3계층형 아키텍처라고도 하는데, 서버의 역할을 크게 WEB, WAS(AP), DB의 3계층으로 나누어서 이러한 이름이 붙었다.

각 서버의 역할(WEB,WAS,DB)에 따라 운영체제 위에서 프로세스가 돌아가며 서버의 자원(CPU, 메모리, 입출력장치)를 활용하고, 각 서버들은 네트워크를 통해 연결되어 요청과 응답을 주고받으며(협업하여) 서비스를 운영한다.

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/497f4b2e-b1ea-4694-b568-34b34ad316bc/030f353b-2f23-4596-804c-de5c4c403d05/Untitled.png)

위의 그림에서 운영체제, 커널, 프로세스에 대해서 생소할 수 있다.

앞에서 공부한 물리적인 구성(서버의 하드웨어, 아키텍처)에서 어떻게 소프트웨어가 작동하고, IT 서비스를 제공할 수 있게 되는지, 논리적인 구성(프로세스, 스레드, 커널)에 대해서 자세히 알아보자.

### 프로세스와 스레드

PC를 켜보면, 파워포인트, LOL 등 다양한 프로그램이 바탕화면에 설치돼있고, 우리는 프로그램을 클릭하여 실행하고, 사용한다.

사실 이러한 프로그램들은 서버가 전원이 꺼져도 데이터가 보존되어야하므로 보조기억장치(HDD, SSD)에서 죽어있다가, 클릭하여 실행하는 순간 프로세스로 살아나고, 메모리에 올라가서 CPU에서 처리하며 동작하게된다.

이러한 일련의 과정을 OS(운영체제)가 총괄하게 되는데, 특히 커널이 핵심 역할을 담당한다.

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/497f4b2e-b1ea-4694-b568-34b34ad316bc/8660d9d0-a690-4c32-82a9-b9d01bd19d28/Untitled.png)

“프로세스”는 “스레드(작업의 최소단위)”로 한번 더 나눌 수 있다. 흔히 프로그래밍 언어를 공부할 때 마주치게되는 “멀티스레딩(Multi Threading)”에서 스레드(Thread)가 여기에 해당한다. 프로그래밍을 할때 프로세스를 사용할지, 스레드를 사용할지는 각각의 장단점과 특성을 충분히 이해한 후 결정해야한다.

프로세스는 독립된 메모리 공간을 가지고 있어 서로의 메모리 공간에 접근하지 못하는 반면에, 스레드는 하나의 프로세스 내에서 하나의 메모리 공간을 공유한다. 따라서 서로 독립적인 프로세스와 다르게, 하나의 스레드에 문제가 생기면 다른 스레드들이 영향을 받는다.

하지만 스레드는 별도의 메모리 공간을 갖고있지 않으므로 프로세스에 비해서 가볍지만, 공유메모리의 하나의 자원에 대해서 여러 스레드가 동시 접근이 가능한 상황을 미리 고려해야한다.

- 독립성 : 프로세스 > 스레드
- 컨텍스트 스위칭 시 부하 : 프로세스 > 스레드
- 신규 생성시 부하 : 프로세스 > 스레드
- 프로그래밍 복잡성 : 프로세스 < 스레드

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/497f4b2e-b1ea-4694-b568-34b34ad316bc/795ffcbd-a66b-47fd-a507-d0af1eaebd1b/Untitled.png)

- `오라클의 PGA, SGA`

### OS 커널

“커널”이란 OS의 핵심 기능을 담당하는 부분이다. 복잡한 OS/하드웨어의 작동 방법을 숨기고, 간단한 인터페이스를 제공한다. 커널 덕분에 개발자들은 하드웨어와 OS의 동작을 하나하나 이해하고, 동작시키기 위한 고민을 할 필요없이, 간단하게 프로그램을 작성하여 하드웨어와 운영체제를 동작시킬 수 있게 되는 것이다.

운영체제의 심장, 커널의 핵심 역할은 총 6가지로 분류할 수 있다.

1. 시스템 콜 인터페이스
2. 프로세스 관리
3. 메모리 관리
4. 네트워크 스택
5. 파일 시스템 관리
6. 장치 드라이버

각각의 역할에 대해서 자세히 알아보자.

**시스템 콜 인터페이스 = 프로세스/스레드에서 커널로 연결되는 통로**

- 애플리케이션(프로세스/스레드)이 OS를 통해서 어떤 처리(네트워크 통신, 디스크 데이터 읽기, … )를 해야할 때, 시스템 콜이라는 통로를 통해서 커널으로 명령을 전달한다.
- 이러한 명령은 시스템 콜 인터페이스를 통해서 전달되고, 수행된다. 커널내에서 이러한 명령이 어떤 과정을 통해서 실행되는지 자세히 몰라도 된다.
- 흔히 우리가 프로그래밍 언어에서 파일을 읽고, 쓰는 일련의 과정은 시스템 콜을 통해서 간단하게 처리된다는 것이다.

**프로세스 관리**

- OS 상에서 프로세스를 생성, 실행, 관리한다.
- 여러 프로세스가 어느 순서로 실행될 지, 어떤 CPU의 코어를 사용할지 등을 관리한다.

**메모리 관리**

- 프로세스에서 사용할 메모리 공간 확보하고 할당해준다.
- 다른 프로세스의 메모리 공간을 침범하지 못하도록 메모리를 관리해준다.

**네트워크 스택**

- 다른 서버와 통신할 때 필요한 소켓(소켓 버퍼, 수신/송신 버퍼)을 생성하고 관리해준다.
- 애플리케이션에서 전송하고자하는 데이터를 세그먼트(패킷)로 분리해준다.

**파일시스템 관리**

- 물리 디스크에 있는 이진 데이터를 사용하기 쉽게 파일 단위로 이용할 수 있도록 인터페이스를 제공해주어, 물리 디스크의 작동 방식에 대해서 알 필요가 없다.
- 프로세스에서도 파일 단위로 데이터를 관리한다.
- 디렉토리 구조를 제공하고, 액세스 관리 등이 가능해진다.

**장치 드라이버**

- 각 제조사에서 운영체제에 적합한 장치 드라이버를 제공하여 장치 내부 작동 과정을 자세하게 알 필요 없이 커널을 통해서 하드웨어 장치를 쉽게 제어할 수 있게 된다.

### 3계층 구조의 시스템의 흐름

3계층 시스템에 대해서 자세히 알아보기에 앞서, 논리적인 구성의 기본이 되는 운영체제와 커널, 프로세스, 스레드에 대해서 알아보았다.

1. 3계층 시스템에서 각 서버는 역할에 맞게 애플리케이션(프로세스/스레드)를 실행한다.
2. 각 애플리케이션의 실행, 데이터읽기/쓰기, 네트워크 통신 등 하드웨어(CPU, 메모리, NIC, … )와 운영체제를 사용해야하는 복잡한 동작들은 모두 커널에 의해서 관리된다.
3. 각 서버는 서로 데이터를 주고받으며, IT 서비스를 제공한다.

로 정리할 수 있겠다.

그러면 3번에서 각 서버가 서로 어떻게 데이터를 주고받고, 어떻게 IT 서비스를 제공하는지 알아볼 차례이다.

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/497f4b2e-b1ea-4694-b568-34b34ad316bc/11bc975c-0bb2-4bd3-9d59-304587e56276/Untitled.png)

구글 크롬을 통해서 유튜브에 접속하는 경우를 예를 들어 설명하겠다.

**흐름 1) 클라이언트(PC) → 웹서버**

1. 클라이언트가 웹 브라우저 프로그램(구글 크롬)을 실행시켜 프로세스를 생성한다.
2. 웹 브라우저(구글 크롬)의 주소창에 특정 사이트(www.youtube.com)를 입력하여 HTTP 요청을 보낸다.
3. 다른 서버로 요청을 보내기위해서는 서버의 IP 주소(223.xxx.xxx.xxx)를 알아야하므로, DNS 서버에 요청을 보내서 이름(www.youtube.com)을 IP 주소로 해석한다.
4. 클라이언트는 해석한 IP 주소를 이용해서 웹 서버(youtube)에 성공적으로 접속하게 되다.
5. 웹서버 역할의 “httpd 프로세스”는 클라이언트가 요청한 콘텐츠의 종류(정적 콘텐츠, 동적 콘텐츠)에 맞게 데이터를 처리하여 반환한다.
   1. 정적콘텐츠 = 낮은 빈도로 변경되는 데이터(로고 이미지, … ) = 웹서버에서 자체적으로 처리
   2. 동적콘텐츠 = 높은 빈도로 변경되는 데이터(조회수 정보, …) = AP서버에서 실시간으로 만들어 줘야하므로 AP서버로 요청을 보낸 후, 응답으로 동적콘텐츠를 받는다.
6. 반환된 콘텐츠는 클라이언트의 화면에 출력된다.

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/497f4b2e-b1ea-4694-b568-34b34ad316bc/6b7c7995-6dce-4864-ace9-443316cdde6b/Untitled.png)

- `DNS 이름해석(Name Resolution)`
- `httpd 프로세스`

**흐름 2) 웹서버 → AP 서버(WAS 서버)**

위에서 정적인 콘텐츠는 웹서버 자체적으로 처리했지만, 동적인 콘텐츠는 AP서버가 전달받아 처리하게 된다.

1. 웹 서버로부터 동적 콘텐츠를 만들어달라는 요청이 도착한다.
2. AP서버 프로세스 내의 스레드가 요청을 받고 자신이 직접 처리해서 반환할 수 있는지, DB서버(youtube 메인 DB서버)의 데이터가 필요한지 판단한다.
3. DB서버의 데이터가 필요하지 않으면, 직접 처리하여 동적인 콘텐츠를 생성하고, 웹서버로 응답을 보낸다.
4. DB서버의 데이터가 필요하면, DB서버로 요청을 보낸다.
   1. DB서버의 데이터를 응답으로 받고, 데이터를 처리해서 동적인 콘텐츠를 생성하고, 웹서버로 응답을 보낸다.
   2. 규모가 작고, 빈번하게 사용해야하는 데이터는 JVM 내부에 데이터를 캐싱하거나, 캐시서버를 DB서버 앞에 두어 요청을 더 빠르게 처리할 수 있다.

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/497f4b2e-b1ea-4694-b568-34b34ad316bc/edc2c9a0-4297-40c6-90a6-268703108b7e/Untitled.png)

- `CDN`

**흐름 3) AP서버 → DB서버**

AP서버는 DB서버에 SQL쿼리문으로 필요한 데이터를 요청하게 되고, SQL쿼리문을 해석(파싱)하여 DB서버의 디스크 또는 메모리에서 필요한 데이터를 꺼내온다.

1. AP서버로부터 요청이 도착한다.
2. DB프로세스가 요청을 받고, 이전에 사용하여 캐싱된 정보가 있는지 확인한다.
3. 캐시된 정보가 없으면, 디스크에서 데이터를 읽어온다.
4. 한번 액세스한 데이터는 캐시 형태로 저장하고, 이후 액세스할때 재사용한다.
5. 요청을 보낸 AP서버로 SQL 요청에 대한 응답을 반환한다.

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/497f4b2e-b1ea-4694-b568-34b34ad316bc/40ac0088-099f-4084-88d6-a20f2909ad9a/Untitled.png)

DB서버의 구체적인 동작은 데이터베이스 종류에 따라 다르고, RDBMS 인지, NoSQL인지, In-memory DB인지에 따라 또 동작방식이 다르다.

- `RDBMS, NoSQL, In-Memory DB`
  - `무엇인지?`
  - `어떻게 동작하는지?`
  - `각각의 장단점은 무엇인지?`
  - `어떤 상황에서 유용한지?`

**흐름 4) AP서버 → 웹서버**

1. DB서버에 요청했던 데이터가 응답으로 반환된다.
2. AP서버의 스레드가 데이터를 가지고 동적 콘텐츠를 생성한다.
3. 동적 콘텐츠를 웹서버에게 반환한다.

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/497f4b2e-b1ea-4694-b568-34b34ad316bc/d6df6fa3-284c-496a-84db-11a2a826e338/Untitled.png)

**흐름 5) 웹서버 → 클라이언트(PC)**

1. AP서버가 동적 콘텐츠를 반환한다.
2. 웹서버 프로세스는 동적콘텐츠를 클라이언트에게 반환한다.
3. 콘텐츠(정적+동적)가 웹 브라우저에 표시된다.

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/497f4b2e-b1ea-4694-b568-34b34ad316bc/9822651b-f52d-41e2-8984-85029fde86e3/Untitled.png)

정리하자면, 각 서버는 다음과 같이 동작한다.

- 프로세스/스레드는 요청을 받는다.
- 요청을 바로 처리하여 반환하고, 필요하다면 별도 서버로 요청을 보낸다.
- 도착한 요청에 대해서 응답을 반환한다.
